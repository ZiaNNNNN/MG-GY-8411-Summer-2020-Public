{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leture 5\n",
    "\n",
    "In this demonstration, we will explore some components of market basket analysis. Using datasets about consumer transactions, we will determine frequent items to generate association rules between items. In a business setting, we could use the association rules for marketing tasks like cross-selling, sales promotions, catalogue design, or discount programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import graphviz\n",
    "\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "\n",
    "# changing some settings\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# indicating paths to files\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "home = os.environ['HOME']\n",
    "path_data = f\"{home}/shared/lecture-5/transactions.txt\"\n",
    "path_data_parquet = f\"{home}/shared/lecture-5/transactions.parquet\"\n",
    "path_images = f\"{home}/shared/lecture-5/images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at three approaches to market basket analysis\n",
    "\n",
    "- Apriori\n",
    "- Eclat \n",
    "- FPGrowth\n",
    "\n",
    "Each approach will allow us to determine frequent patterns and association rules. We will work with two datasets containing records of consumer transactions.\n",
    "\n",
    "### Example 1 \n",
    "\n",
    "The Apriori approach to market basket analysis involves two steps\n",
    "\n",
    "- join \n",
    "   * generate candidate itemsets from combinations of frequent itemsets\n",
    "- prune\n",
    "   * remove infrequent candidate itemsets to determine frequent itemsets \n",
    "\n",
    "We have the transactions stored in `transactions_example.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1 I2 I5 T1\r\n",
      "I2 I4 T2\r\n",
      "I2 I3 T3\r\n",
      "I1 I2 I4 T4\r\n",
      "I1 I3 T5\r\n",
      "I2 I3 T6\r\n",
      "I1 I3 T7\r\n",
      "I1 I2 I3 I5 T8\r\n",
      "I1 I2 I3 T9"
     ]
    }
   ],
   "source": [
    "!cat transactions_example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `cat` command for the command line interface allows us to view the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transactions_example.txt\") as file_handle:\n",
    "    lines = file_handle.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the lines into `lines` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I1', 'I2', 'I5'],\n",
       " ['I2', 'I4'],\n",
       " ['I2', 'I3'],\n",
       " ['I1', 'I2', 'I4'],\n",
       " ['I1', 'I3'],\n",
       " ['I2', 'I3'],\n",
       " ['I1', 'I3'],\n",
       " ['I1', 'I2', 'I3', 'I5'],\n",
       " ['I1', 'I2', 'I3']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = [line.split(\" \")[0:-1] for line in lines]\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the identifiers for the transactions `T1`,...,`T9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_transactions = len(transactions)\n",
    "number_of_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that we have 9 transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1', 'I2', 'I3', 'I4', 'I5'], dtype='<U2')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = []\n",
    "\n",
    "for transaction in transactions:\n",
    "    items = items + transaction\n",
    "\n",
    "items = np.unique(items)\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the transactions contains items from an inventory of 5 products `I1`,...,`I5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_absolute_support = 2\n",
    "\n",
    "minimum_support = minimum_absolute_support / number_of_transactions \n",
    "minimum_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the minimum absolute support to 2 transactions. So a frequent itemset must appear in at least 22\\% of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"all_itemsets.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 1-Itemsets\n",
    "\n",
    "We can determine the frequent 1-itemsets by scanning the transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I1': 6, 'I2': 7, 'I3': 6, 'I4': 2, 'I5': 2}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_candidates_1 = dict().fromkeys(items, 0)\n",
    "\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        counts_candidates_1[item] += 1 \n",
    "        \n",
    "counts_candidates_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had 9 iterations because we have 9 transactions. For each iteration, we look through the different items in the transaction. \n",
    "\n",
    "Scanning the records involves 23 operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I1', 'I2', 'I3', 'I4', 'I5']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_1 = []\n",
    "\n",
    "for key, value in counts_candidates_1.items():\n",
    "    if value >= minimum_absolute_support:\n",
    "        itemset_1.append(key)\n",
    "\n",
    "itemset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that all of the items appear in at least 2 transactions. So we did not need to prune any candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"itemsets_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 2-Itemsets\n",
    "\n",
    "We need to determine the candidate 2-itemsets from combinations of the frequent 1-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I1', 'I2'),\n",
       " ('I1', 'I3'),\n",
       " ('I1', 'I4'),\n",
       " ('I1', 'I5'),\n",
       " ('I2', 'I3'),\n",
       " ('I2', 'I4'),\n",
       " ('I2', 'I5'),\n",
       " ('I3', 'I4'),\n",
       " ('I3', 'I5'),\n",
       " ('I4', 'I5')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations_itemset_1 = []\n",
    "\n",
    "for item_1 in itemset_1:\n",
    "    for item_2 in itemset_1:\n",
    "        if item_1 < item_2:\n",
    "            combinations_itemset_1.append((item_1, item_2))\n",
    "\n",
    "combinations_itemset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid duplicate pairs by sorting the labels for the items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_1[0] < itemset_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `I1` is less than `I2`\n",
    "\n",
    "- the first characters are equal \n",
    "- the second characters have order `1 < 2` \n",
    "\n",
    "We call this lexicographic ordering. It reminds us of the order of words in an English dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('I1', 'I2'): 4,\n",
       " ('I1', 'I3'): 4,\n",
       " ('I1', 'I4'): 1,\n",
       " ('I1', 'I5'): 2,\n",
       " ('I2', 'I3'): 4,\n",
       " ('I2', 'I4'): 2,\n",
       " ('I2', 'I5'): 2,\n",
       " ('I3', 'I4'): 0,\n",
       " ('I3', 'I5'): 1,\n",
       " ('I4', 'I5'): 0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_candidates_2 = dict().fromkeys(combinations_itemset_1, 0)\n",
    "\n",
    "for transaction in transactions:\n",
    "    for pair in combinations_itemset_1:\n",
    "        if set(pair).issubset(set(transaction)):\n",
    "            counts_candidates_2[pair] += 1 \n",
    "            \n",
    "counts_candidates_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had 9 iterations because we have 9 transactions. For each iteration, we look for each of the 10 candidate 1-itemsets.\n",
    "\n",
    "Scanning the records involves 90 operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I1', 'I2'),\n",
       " ('I1', 'I3'),\n",
       " ('I1', 'I5'),\n",
       " ('I2', 'I3'),\n",
       " ('I2', 'I4'),\n",
       " ('I2', 'I5')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_2 = []\n",
    "\n",
    "for key, value in counts_candidates_2.items():\n",
    "    if value >= minimum_absolute_support:\n",
    "        itemset_2.append(key)\n",
    "\n",
    "itemset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the infrequent itemsets from the candidate 2-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_candidates_2) - len(itemset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that 4 of the candidate 2-itemsets appear in fewer than 2 transactions. So we need to prune these candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"itemsets_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 3-Itemsets\n",
    "\n",
    "We need to determine the candidate 3-itemsets from combinations of the frequent 2-itemsets and frequent 1-itemsets.\n",
    "\n",
    "Again, we can avoid duplicate pairs by sorting the labels for the items. We use lexicographic ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I1', 'I2', 'I3'),\n",
       " ('I1', 'I2', 'I4'),\n",
       " ('I1', 'I2', 'I5'),\n",
       " ('I1', 'I3', 'I4'),\n",
       " ('I1', 'I3', 'I5'),\n",
       " ('I1', 'I4', 'I5'),\n",
       " ('I2', 'I3', 'I4'),\n",
       " ('I2', 'I3', 'I5'),\n",
       " ('I2', 'I4', 'I5'),\n",
       " ('I3', 'I4', 'I5')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations_itemset_1_itemset_2 = []\n",
    "\n",
    "for item_1 in itemset_1:\n",
    "    for item_2 in combinations_itemset_1:\n",
    "        if item_1 < item_2[0]:\n",
    "            combinations_itemset_1_itemset_2.append((item_1, item_2[0], item_2[1]))\n",
    "\n",
    "combinations_itemset_1_itemset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we count the number of occurrences of the candidate 3-itemsets, we need to prune any candidate 3-itemset containing an infrequent 2-itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I1', 'I2', 'I3'),\n",
       " ('I1', 'I2', 'I5'),\n",
       " ('I1', 'I3', 'I5'),\n",
       " ('I2', 'I3', 'I4'),\n",
       " ('I2', 'I4', 'I5')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for combination in combinations_itemset_1_itemset_2:\n",
    "    condition_1 = (combination[0], combination[1]) in itemset_2\n",
    "    condition_2 = (combination[0], combination[2]) in itemset_2\n",
    "    condition_3 = (combination[1], combination[2]) in itemset_2\n",
    "    \n",
    "    if not (condition_1 and condition_2 and condition_3):\n",
    "        combinations_itemset_1_itemset_2.remove(combination)\n",
    "        \n",
    "combinations_itemset_1_itemset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove 6 candidate 3-itemsets. \n",
    "\n",
    "Now we can count the number of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('I1', 'I2', 'I3'): 2,\n",
       " ('I1', 'I2', 'I5'): 2,\n",
       " ('I1', 'I3', 'I5'): 1,\n",
       " ('I2', 'I3', 'I4'): 0,\n",
       " ('I2', 'I4', 'I5'): 0}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_candidates_3 = dict().fromkeys(combinations_itemset_1_itemset_2, 0)\n",
    "\n",
    "for transaction in transactions:\n",
    "    for triple in combinations_itemset_1_itemset_2:\n",
    "        if set(triple).issubset(set(transaction)):\n",
    "            counts_candidates_3[triple] += 1 \n",
    "            \n",
    "counts_candidates_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had 9 iterations because we have 9 transactions. For each iteration, we look for each of the 5 candidate 1-itemsets.\n",
    "\n",
    "Scanning the records involves 45 operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I1', 'I2', 'I3'), ('I1', 'I2', 'I5')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_3 = []\n",
    "\n",
    "for key, value in counts_candidates_3.items():\n",
    "    if value >= minimum_absolute_support:\n",
    "        itemset_3.append(key)\n",
    "\n",
    "itemset_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the infrequent itemsets from the candidate 2-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_candidates_3) - len(itemset_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that 3 of the candidate 3-itemsets appear in fewer than 2 transactions. So we need to prune these candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"itemsets_3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of Search\n",
    "\n",
    "The Apriori approach is a breadth-first search. Here the phrase breadth-first search means that we need to study all of the frequent $k$-itemsets before we can study the frequent $k+1$-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"itemsets_bfs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each transaction, we stored a basket of items. Instead we could change the approach to storing the records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I1': [1, 4, 5, 7, 8, 9],\n",
       " 'I2': [1, 2, 3, 4, 6, 8, 9],\n",
       " 'I3': [3, 5, 6, 7, 8, 9],\n",
       " 'I4': [2, 4],\n",
       " 'I5': [1, 8]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_counts = dict().fromkeys(items, [])\n",
    "\n",
    "for idx, transaction in enumerate(transactions):\n",
    "    for key, value in item_counts.items():\n",
    "        if key in transaction:\n",
    "            item_counts[key] = value + [idx + 1] \n",
    "\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each item, we could store a list of transactions. Now we can directly compare the occurences of items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 8}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_item2_item5 = set(item_counts[\"I2\"]).intersection(set(item_counts[\"I5\"]))\n",
    "\n",
    "transaction_item2_item5_item1 = transaction_item2_item5.intersection(set(item_counts[\"I1\"]))\n",
    "\n",
    "transaction_item2_item5_item1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can determine that transaction 1 and transaction 8 both include `I1`, `I2` and `I5`. We did not need to study other frequent itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_images+\"itemsets_dfs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "The Eclat approach to market basket analysis uses depth first search instead of breadth first search. We need to rearrange the data to store transactions for each item rather than items for each transaction. After we rearrange the data, we have two steps \n",
    "\n",
    "- join \n",
    "   * generate candidate itemsets from combinations of frequent itemsets\n",
    "- prune\n",
    "   * form intersections of sets of transactions\n",
    "\n",
    "So Apriori and Eclat have the same join step and different prune step.\n",
    "\n",
    "We have the transactions stored in `shared/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRO11987 ELE17451 ELE89019 SNA90258 GRO99222 \r\n",
      "GRO99222 GRO12298 FRO12685 ELE91550 SNA11465 ELE26917 ELE52966 FRO90334 SNA30755 ELE17451 FRO84225 SNA80192 \r\n",
      "ELE17451 GRO73461 DAI22896 SNA99873 FRO86643 \r\n",
      "ELE17451 ELE37798 FRO86643 GRO56989 ELE23393 SNA11465 \r\n",
      "ELE17451 SNA69641 FRO86643 FRO78087 SNA11465 GRO39357 ELE28573 ELE11375 DAI54444 \r\n",
      "ELE17451 GRO73461 DAI22896 SNA99873 FRO18919 DAI50921 SNA80192 GRO75578 \r\n",
      "ELE17451 ELE59935 FRO18919 ELE23393 SNA80192 SNA85662 SNA91554 DAI22177 \r\n",
      "ELE17451 SNA69641 FRO18919 SNA90258 ELE28573 ELE11375 DAI14125 FRO78087 \r\n",
      "ELE17451 GRO73461 DAI22896 SNA80192 SNA85662 SNA90258 DAI46755 FRO81176 ELE66810 DAI49199 DAI91535 GRO94758 ELE94711 DAI22177 \r\n",
      "ELE17451 SNA69641 DAI91535 GRO94758 GRO99222 FRO76833 FRO81176 SNA80192 DAI54690 ELE37798 GRO56989 \r\n"
     ]
    }
   ],
   "source": [
    "!head ~/shared/lecture-5/transactions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `head` command for the command line interface allows us to view the first 5 lines of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data) as file_handle:\n",
    "    lines = file_handle.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the lines into `lines` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRO11987', 'ELE17451', 'ELE89019', 'SNA90258', 'GRO99222']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = [line.split(\" \")[0:-1] for line in lines]\n",
    "transactions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a larger dataset than Example 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31101"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_transactions = len(transactions)\n",
    "number_of_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that we have 31101 transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_combined = []\n",
    "\n",
    "for transaction in transactions:\n",
    "    transactions_combined += transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the items across transactions to determine the size of the inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12592"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = np.unique(transactions_combined)\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the transactions contains items from an inventory of 12592 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003215330696762162"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_absolute_support = 100\n",
    "\n",
    "minimum_support = minimum_absolute_support / number_of_transactions \n",
    "minimum_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the minimum absolute support to 100 transactions. So a frequent itemset must appear in at least 0.3\\% of transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row Oriented Format\n",
    "\n",
    "We can store the records in a table. The table has \n",
    "\n",
    "- rows consisting of transactions\n",
    "- columns consisting of distinct items \n",
    "\n",
    "We have entry 1 to indicate the inclusion of an item in the transaction. Otherwise we have 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAI11153</th>\n",
       "      <th>DAI11223</th>\n",
       "      <th>DAI11238</th>\n",
       "      <th>DAI11257</th>\n",
       "      <th>...</th>\n",
       "      <th>DAI46827</th>\n",
       "      <th>DAI46863</th>\n",
       "      <th>DAI46921</th>\n",
       "      <th>DAI46953</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAI11153  DAI11223  DAI11238  DAI11257  ...  DAI46827  DAI46863  \\\n",
       "0           0         0         0         0  ...         0         0   \n",
       "1           0         0         0         0  ...         0         0   \n",
       "2           0         0         0         0  ...         0         0   \n",
       "3           0         0         0         0  ...         0         0   \n",
       "4           0         0         0         0  ...         0         0   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "995         0         0         0         0  ...         0         0   \n",
       "996         0         0         0         0  ...         0         0   \n",
       "997         0         0         0         0  ...         0         0   \n",
       "998         0         0         0         0  ...         0         0   \n",
       "999         0         0         0         0  ...         0         0   \n",
       "\n",
       "     DAI46921  DAI46953  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "995         0         0  \n",
       "996         0         0  \n",
       "997         0         0  \n",
       "998         0         0  \n",
       "999         0         0  \n",
       "\n",
       "[1000 rows x 1000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_parquet(path_data_parquet)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the table take 8MB of space in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have just stored 1000 rows and 1000 columns. If we included all transactions and all products, then the table would take 3GB of space in memory. \n",
    "\n",
    "\n",
    "Note that the table contains the value 0 for many entries. We can rearrange the data to reduce the size of the table through exlusion of the value 0.\n",
    "\n",
    "#### Column Oriented Format\n",
    "\n",
    "We can store the records in a dictionary. The dictionary has \n",
    "\n",
    "- keys consisting of items\n",
    "- values consisting of sets of transactions \n",
    "\n",
    "We record all of the transactions containing an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13917, 14585, 17989, 18020, 18108, 18249, 21404, 21444}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_column_format = dict().fromkeys(items, set())\n",
    "\n",
    "for idx, transaction in enumerate(transactions):\n",
    "    for item in transaction:\n",
    "        table_column_format[item] = table_column_format[item].union({idx})\n",
    "\n",
    "table_column_format[\"DAI11153\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 1-Itemsets\n",
    "\n",
    "We will use the `pandas` package to process the dataset because we have more transactions and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_1 = pd.Series(table_column_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the candidate 1-itemsets through comparison with the minimum absolute support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAI11223</th>\n",
       "      <td>{4105, 4106, 27658, 5135, 3607, 4124, 3624, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI11778</th>\n",
       "      <td>{19714, 16131, 5124, 3846, 3847, 776, 3850, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI13194</th>\n",
       "      <td>{8965, 6406, 8966, 6408, 8969, 10757, 12809, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI13266</th>\n",
       "      <td>{28676, 9221, 18952, 521, 18953, 9739, 9230, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI13788</th>\n",
       "      <td>{24577, 15875, 7684, 13830, 5128, 8200, 26122,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA96466</th>\n",
       "      <td>{22528, 19461, 24581, 24582, 24583, 24584, 245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA97370</th>\n",
       "      <td>{28417, 5378, 30469, 17415, 17419, 19467, 1972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA97586</th>\n",
       "      <td>{17920, 6658, 5124, 8709, 10760, 5642, 11274, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA99654</th>\n",
       "      <td>{9219, 22022, 25608, 22538, 20492, 27663, 4113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA99873</th>\n",
       "      <td>{24577, 2, 5, 8202, 13, 29, 24605, 24606, 35, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transactions\n",
       "DAI11223  {4105, 4106, 27658, 5135, 3607, 4124, 3624, 36...\n",
       "DAI11778  {19714, 16131, 5124, 3846, 3847, 776, 3850, 16...\n",
       "DAI13194  {8965, 6406, 8966, 6408, 8969, 10757, 12809, 2...\n",
       "DAI13266  {28676, 9221, 18952, 521, 18953, 9739, 9230, 5...\n",
       "DAI13788  {24577, 15875, 7684, 13830, 5128, 8200, 26122,...\n",
       "...                                                     ...\n",
       "SNA96466  {22528, 19461, 24581, 24582, 24583, 24584, 245...\n",
       "SNA97370  {28417, 5378, 30469, 17415, 17419, 19467, 1972...\n",
       "SNA97586  {17920, 6658, 5124, 8709, 10760, 5642, 11274, ...\n",
       "SNA99654  {9219, 22022, 25608, 22538, 20492, 27663, 4113...\n",
       "SNA99873  {24577, 2, 5, 8202, 13, 29, 24605, 24606, 35, ...\n",
       "\n",
       "[647 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_1 = candidate_1[candidate_1.map(lambda x : len(x)) >= minimum_absolute_support]\n",
    "\n",
    "itemset_1 = itemset_1.to_frame()\n",
    "itemset_1.columns = [\"transactions\"]\n",
    "itemset_1 = itemset_1.sort_index()\n",
    "\n",
    "itemset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 647 frequent 1-itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 2-Itemsets\n",
    "\n",
    "We can generate candidate 2-itemsets from combinations of frequent 1-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAI11223  DAI11778                                                   {}\n",
       "          DAI13194                                              {10446}\n",
       "          DAI13266                                              {29868}\n",
       "          DAI13788                                                   {}\n",
       "          DAI13902                                       {17475, 25542}\n",
       "                                            ...                        \n",
       "SNA97370  SNA99654                                                   {}\n",
       "          SNA99873    {5568, 13636, 13732, 5225, 5323, 31084, 5326, ...\n",
       "SNA97586  SNA99654                                                   {}\n",
       "          SNA99873    {26497, 5316, 26212, 7652, 10760, 23500, 1745,...\n",
       "SNA99654  SNA99873    {6280, 8072, 7307, 9614, 7962, 2977, 2466, 308...\n",
       "Length: 208981, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_2 = dict()\n",
    "\n",
    "for item_1, transaction_1 in itemset_1[\"transactions\"].iteritems():\n",
    "    for item_2, transaction_2 in itemset_1[\"transactions\"].iteritems():\n",
    "        if item_1 < item_2:\n",
    "            candidate_2[(item_1, item_2)] = transaction_1.intersection(transaction_2)\n",
    "\n",
    "candidate_2 = pd.Series(candidate_2)\n",
    "candidate_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the candidate 2-itemsets through comparison with the minimum absolute support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAI16732</th>\n",
       "      <th>FRO78087</th>\n",
       "      <td>{4609, 22019, 4615, 10249, 4620, 3605, 12826, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI18527</th>\n",
       "      <th>SNA44451</th>\n",
       "      <td>{13320, 11790, 9237, 27158, 9750, 9247, 5669, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DAI22177</th>\n",
       "      <th>DAI31081</th>\n",
       "      <td>{12803, 29700, 5130, 12812, 10764, 6681, 19995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI62779</th>\n",
       "      <td>{22534, 22535, 20492, 26643, 22561, 20516, 413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI63921</th>\n",
       "      <td>{6657, 19971, 12817, 26642, 8723, 11282, 6681,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SNA80324</th>\n",
       "      <th>SNA93860</th>\n",
       "      <td>{24576, 9736, 25098, 27148, 8206, 8207, 12304,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA96271</th>\n",
       "      <td>{24581, 24072, 5130, 5643, 14346, 18955, 6668,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA99873</th>\n",
       "      <td>{8705, 5643, 8719, 5647, 7184, 19480, 8731, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA90094</th>\n",
       "      <th>SNA96271</th>\n",
       "      <td>{6656, 8709, 7697, 10770, 23066, 7711, 10784, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA93860</th>\n",
       "      <th>SNA99873</th>\n",
       "      <td>{19989, 7194, 19999, 11298, 7207, 6697, 9774, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        transactions\n",
       "DAI16732 FRO78087  {4609, 22019, 4615, 10249, 4620, 3605, 12826, ...\n",
       "DAI18527 SNA44451  {13320, 11790, 9237, 27158, 9750, 9247, 5669, ...\n",
       "DAI22177 DAI31081  {12803, 29700, 5130, 12812, 10764, 6681, 19995...\n",
       "         DAI62779  {22534, 22535, 20492, 26643, 22561, 20516, 413...\n",
       "         DAI63921  {6657, 19971, 12817, 26642, 8723, 11282, 6681,...\n",
       "...                                                              ...\n",
       "SNA80324 SNA93860  {24576, 9736, 25098, 27148, 8206, 8207, 12304,...\n",
       "         SNA96271  {24581, 24072, 5130, 5643, 14346, 18955, 6668,...\n",
       "         SNA99873  {8705, 5643, 8719, 5647, 7184, 19480, 8731, 11...\n",
       "SNA90094 SNA96271  {6656, 8709, 7697, 10770, 23066, 7711, 10784, ...\n",
       "SNA93860 SNA99873  {19989, 7194, 19999, 11298, 7207, 6697, 9774, ...\n",
       "\n",
       "[1334 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_2 = candidate_2[candidate_2.map(lambda x : len(x)) >= minimum_absolute_support]\n",
    "\n",
    "itemset_2 = itemset_2.to_frame()\n",
    "itemset_2.columns = [\"transactions\"]\n",
    "itemset_2 = itemset_2.sort_index()\n",
    "\n",
    "itemset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1334 frequent 2-itemsets.\n",
    "\n",
    "Having computed the frequent 2-itemsets, we can calculate the confidence for all association rules of the form \n",
    "\n",
    "> `Item 1` implies `Item 2`\n",
    "\n",
    "Note that confidence reflects the certainty of the association rule\n",
    "\n",
    "$$\\displaystyle \\frac{\\text{Support of \\{Item 1, Item 2\\}}}{\\text{Support of Item 1}}$$\n",
    "\n",
    "We need to count the number of occurrences of \n",
    "\n",
    "- `Item 1`\n",
    "- `Item 1` and `Item 2`\n",
    "\n",
    "So we will use both the frequent 1-itemsets and the frequent 2-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_order_1 = []\n",
    "confidence_order_2 = []\n",
    "\n",
    "for item, transaction in itemset_2[\"transactions\"].iteritems():\n",
    "    ratio = len(transaction) / len(itemset_1.loc[item[0], \"transactions\"]) \n",
    "    confidence_order_1.append(ratio)\n",
    "    \n",
    "    ratio = len(transaction) / len(itemset_1.loc[item[1], \"transactions\"]) \n",
    "    confidence_order_2.append(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need to consider the pairs of items in both orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>confidence_order_1</th>\n",
       "      <th>confidence_order_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DAI62779</th>\n",
       "      <th>GRO17075</th>\n",
       "      <td>{5120, 15873, 29698, 5123, 14340, 17929, 12301...</td>\n",
       "      <td>0.014999</td>\n",
       "      <td>0.383142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA31619</th>\n",
       "      <td>{19457, 5127, 18954, 5134, 19986, 18965, 10784...</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.359431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA55617</th>\n",
       "      <td>{14360, 7711, 11812, 27176, 9275, 21565, 9279,...</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.259640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA74022</th>\n",
       "      <td>{6667, 11799, 5167, 6703, 9267, 6709, 14392, 6...</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.353147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA82528</th>\n",
       "      <td>{2049, 15879, 15880, 15881, 20492, 18961, 2255...</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.170034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI23334</th>\n",
       "      <th>DAI62779</th>\n",
       "      <td>{23050, 8206, 8207, 23061, 19990, 19993, 23066...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.040948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI43868</th>\n",
       "      <th>SNA82528</th>\n",
       "      <td>{20482, 21507, 21506, 21510, 23047, 21513, 204...</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI88079</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{30721, 30725, 14345, 8202, 6155, 8204, 22539,...</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.114919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELE12951</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{22027, 23566, 17940, 11290, 8730, 539, 7711, ...</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.027055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI93865</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{8705, 26115, 24071, 13832, 27144, 9739, 15372...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        transactions  \\\n",
       "DAI62779 GRO17075  {5120, 15873, 29698, 5123, 14340, 17929, 12301...   \n",
       "         SNA31619  {19457, 5127, 18954, 5134, 19986, 18965, 10784...   \n",
       "         SNA55617  {14360, 7711, 11812, 27176, 9275, 21565, 9279,...   \n",
       "         SNA74022  {6667, 11799, 5167, 6703, 9267, 6709, 14392, 6...   \n",
       "         SNA82528  {2049, 15879, 15880, 15881, 20492, 18961, 2255...   \n",
       "...                                                              ...   \n",
       "DAI23334 DAI62779  {23050, 8206, 8207, 23061, 19990, 19993, 23066...   \n",
       "DAI43868 SNA82528  {20482, 21507, 21506, 21510, 23047, 21513, 204...   \n",
       "DAI88079 FRO40251  {30721, 30725, 14345, 8202, 6155, 8204, 22539,...   \n",
       "ELE12951 FRO40251  {22027, 23566, 17940, 11290, 8730, 539, 7711, ...   \n",
       "DAI93865 FRO40251  {8705, 26115, 24071, 13832, 27144, 9739, 15372...   \n",
       "\n",
       "                   confidence_order_1  confidence_order_2  \n",
       "DAI62779 GRO17075            0.014999            0.383142  \n",
       "         SNA31619            0.015149            0.359431  \n",
       "         SNA55617            0.015149            0.259640  \n",
       "         SNA74022            0.015149            0.353147  \n",
       "         SNA82528            0.015149            0.170034  \n",
       "...                               ...                 ...  \n",
       "DAI23334 DAI62779            0.954545            0.040948  \n",
       "DAI43868 SNA82528            0.972973            0.484848  \n",
       "DAI88079 FRO40251            0.986726            0.114919  \n",
       "ELE12951 FRO40251            0.990566            0.027055  \n",
       "DAI93865 FRO40251            1.000000            0.053594  \n",
       "\n",
       "[1334 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_2_with_confidence = itemset_2.copy()\n",
    "\n",
    "itemset_2_with_confidence[\"confidence_order_1\"] = confidence_order_1\n",
    "itemset_2_with_confidence[\"confidence_order_2\"] = confidence_order_2\n",
    "\n",
    "itemset_2_with_confidence.sort_values(\"confidence_order_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that many frequent 2-itemsets have high confidence. For example \n",
    "\n",
    "> `DAI93865` implies `FRO40251` \n",
    "\n",
    "has confidence 1. So item `FRO40251` appears alongside `DAI93865` in all transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent 3-Itemsets\n",
    "\n",
    "We can generate candidate 3-itemsets from combinations of frequent 1-itemsets and frequent 2-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAI16732  FRO78087  FRO78994                                                   {}\n",
       "                    FRO79022            {12261, 10249, 20307, 22841, 20605, 9183}\n",
       "                    FRO80039    {22019, 3429, 3622, 22856, 12232, 12268, 12269...\n",
       "                    FRO80238                                                {196}\n",
       "                    FRO81176                                 {12849, 12261, 3622}\n",
       "                                                      ...                        \n",
       "SNA90094  SNA96271  SNA96466                                {19450, 20975, 20335}\n",
       "                    SNA97370                                                   {}\n",
       "                    SNA97586                                        {23066, 8709}\n",
       "                    SNA99654                                        {8506, 21471}\n",
       "                    SNA99873                     {7850, 21968, 5328, 10770, 5947}\n",
       "Length: 306979, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_3 = dict()\n",
    "\n",
    "for item_1, transaction_1 in itemset_2[\"transactions\"].iteritems():\n",
    "    for item_2, transaction_2 in itemset_1[\"transactions\"].iteritems():\n",
    "        if item_1[1] < item_2:\n",
    "            candidate_3[(item_1[0], item_1[1], item_2)] = transaction_1.intersection(transaction_2)\n",
    "\n",
    "candidate_3 = pd.Series(candidate_3)\n",
    "candidate_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the candidate 3-itemsets through comparison with the minimum absolute support.\n",
    "\n",
    "Note that we did not have to check all 2-itemsets within the candidate 3-itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAI22896</th>\n",
       "      <th>DAI62779</th>\n",
       "      <th>GRO73461</th>\n",
       "      <td>{8706, 2050, 8709, 19977, 8714, 10762, 8719, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI23334</th>\n",
       "      <th>DAI62779</th>\n",
       "      <th>ELE92920</th>\n",
       "      <td>{23061, 19990, 19993, 23066, 17950, 17951, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DAI31081</th>\n",
       "      <th>DAI62779</th>\n",
       "      <th>ELE17451</th>\n",
       "      <td>{5123, 19977, 5130, 19978, 19980, 2061, 8205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI75645</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{30721, 5122, 7176, 25097, 5130, 8203, 9226, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELE32164</th>\n",
       "      <th>GRO59710</th>\n",
       "      <td>{4609, 12305, 26645, 5156, 4136, 5674, 24624, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">FRO40251</th>\n",
       "      <th>GRO94758</th>\n",
       "      <th>SNA80324</th>\n",
       "      <td>{8705, 5635, 8203, 5644, 18967, 4122, 5147, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA45677</th>\n",
       "      <th>SNA80324</th>\n",
       "      <td>{8192, 30721, 5130, 5133, 5140, 11291, 17947, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA55762</th>\n",
       "      <th>SNA80324</th>\n",
       "      <td>{8705, 5642, 9227, 8203, 5133, 12302, 22027, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA80324</th>\n",
       "      <th>SNA96271</th>\n",
       "      <td>{5130, 6668, 12306, 19479, 18461, 11297, 9763,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRO73056</th>\n",
       "      <th>GRO44993</th>\n",
       "      <th>GRO73461</th>\n",
       "      <td>{7168, 1028, 9223, 9224, 7177, 523, 529, 7697,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transactions\n",
       "DAI22896 DAI62779 GRO73461  {8706, 2050, 8709, 19977, 8714, 10762, 8719, 2...\n",
       "DAI23334 DAI62779 ELE92920  {23061, 19990, 19993, 23066, 17950, 17951, 200...\n",
       "DAI31081 DAI62779 ELE17451  {5123, 19977, 5130, 19978, 19980, 2061, 8205, ...\n",
       "         DAI75645 FRO40251  {30721, 5122, 7176, 25097, 5130, 8203, 9226, 7...\n",
       "         ELE32164 GRO59710  {4609, 12305, 26645, 5156, 4136, 5674, 24624, ...\n",
       "...                                                                       ...\n",
       "FRO40251 GRO94758 SNA80324  {8705, 5635, 8203, 5644, 18967, 4122, 5147, 17...\n",
       "         SNA45677 SNA80324  {8192, 30721, 5130, 5133, 5140, 11291, 17947, ...\n",
       "         SNA55762 SNA80324  {8705, 5642, 9227, 8203, 5133, 12302, 22027, 1...\n",
       "         SNA80324 SNA96271  {5130, 6668, 12306, 19479, 18461, 11297, 9763,...\n",
       "FRO73056 GRO44993 GRO73461  {7168, 1028, 9223, 9224, 7177, 523, 529, 7697,...\n",
       "\n",
       "[233 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_3 = candidate_3[candidate_3.map(lambda x : len(x)) >= minimum_absolute_support]\n",
    "\n",
    "itemset_3 = itemset_3.to_frame()\n",
    "itemset_3.columns = [\"transactions\"]\n",
    "itemset_3 = itemset_3.sort_index()\n",
    "\n",
    "itemset_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the confidence for association rules of the form\n",
    "\n",
    "> `Item 1, Item 2` imply `Item 3`\n",
    "\n",
    "We need to count the number of occurrences of \n",
    "\n",
    "- `Item 1` and `Item 2`\n",
    "- `Item 1`, `Item 2`, `Item 3`\n",
    "\n",
    "So we will use both the frequent 2-itemsets and the frequent 3-itemsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_order_1 = []\n",
    "confidence_order_2 = []\n",
    "confidence_order_3 = []\n",
    "\n",
    "for item, transaction in itemset_3[\"transactions\"].iteritems():\n",
    "    ratio = len(transaction) / len(itemset_2.loc[(item[0], item[1]), \"transactions\"]) \n",
    "    confidence_order_1.append(ratio)\n",
    "\n",
    "    ratio = len(transaction) / len(itemset_2.loc[(item[0], item[2]), \"transactions\"]) \n",
    "    confidence_order_2.append(ratio)\n",
    "    \n",
    "    ratio = len(transaction) / len(itemset_2.loc[(item[1], item[2]), \"transactions\"]) \n",
    "    confidence_order_3.append(ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have three pairs of items for each triple of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>confidence_order_1</th>\n",
       "      <th>confidence_order_2</th>\n",
       "      <th>confidence_order_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DAI62779</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ELE17451</th>\n",
       "      <th>SNA90094</th>\n",
       "      <td>{10770, 19486, 10784, 5156, 21029, 5164, 20017...</td>\n",
       "      <td>0.064698</td>\n",
       "      <td>0.252451</td>\n",
       "      <td>0.565934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRO31317</th>\n",
       "      <td>{8199, 9735, 5142, 11298, 35, 37, 38, 20012, 4...</td>\n",
       "      <td>0.066583</td>\n",
       "      <td>0.281915</td>\n",
       "      <td>0.295265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA72163</th>\n",
       "      <td>{19977, 10762, 19978, 19980, 19981, 15896, 292...</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>0.383513</td>\n",
       "      <td>0.393382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELE56788</th>\n",
       "      <td>{19977, 19980, 15896, 19998, 9762, 8747, 21041...</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>0.301408</td>\n",
       "      <td>0.514423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRO46854</th>\n",
       "      <td>{8198, 9735, 8715, 8716, 23073, 9762, 20007, 8...</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.236443</td>\n",
       "      <td>0.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRO19221</th>\n",
       "      <th>SNA53220</th>\n",
       "      <th>SNA93860</th>\n",
       "      <td>{2571, 3605, 4134, 3112, 4649, 4665, 4154, 466...</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.448819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI42083</th>\n",
       "      <th>DAI62779</th>\n",
       "      <th>DAI92600</th>\n",
       "      <td>{29696, 29697, 29698, 29708, 29710, 29202, 292...</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI88079</th>\n",
       "      <th>ELE17451</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{14345, 5130, 8202, 8204, 25097, 26122, 28175,...</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.275785</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI75645</th>\n",
       "      <th>DAI88079</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{30721, 19460, 14345, 5130, 8202, 8204, 22539,...</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.118022</td>\n",
       "      <td>0.331839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI62779</th>\n",
       "      <th>DAI88079</th>\n",
       "      <th>FRO40251</th>\n",
       "      <td>{19460, 30216, 14345, 8202, 5130, 6155, 8204, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109346</td>\n",
       "      <td>0.262332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transactions  \\\n",
       "DAI62779 ELE17451 SNA90094  {10770, 19486, 10784, 5156, 21029, 5164, 20017...   \n",
       "                  FRO31317  {8199, 9735, 5142, 11298, 35, 37, 38, 20012, 4...   \n",
       "                  SNA72163  {19977, 10762, 19978, 19980, 19981, 15896, 292...   \n",
       "                  ELE56788  {19977, 19980, 15896, 19998, 9762, 8747, 21041...   \n",
       "                  GRO46854  {8198, 9735, 8715, 8716, 23073, 9762, 20007, 8...   \n",
       "...                                                                       ...   \n",
       "FRO19221 SNA53220 SNA93860  {2571, 3605, 4134, 3112, 4649, 4665, 4154, 466...   \n",
       "DAI42083 DAI62779 DAI92600  {29696, 29697, 29698, 29708, 29710, 29202, 292...   \n",
       "DAI88079 ELE17451 FRO40251  {14345, 5130, 8202, 8204, 25097, 26122, 28175,...   \n",
       "DAI75645 DAI88079 FRO40251  {30721, 19460, 14345, 5130, 8202, 8204, 22539,...   \n",
       "DAI62779 DAI88079 FRO40251  {19460, 30216, 14345, 8202, 5130, 6155, 8204, ...   \n",
       "\n",
       "                            confidence_order_1  confidence_order_2  \\\n",
       "DAI62779 ELE17451 SNA90094            0.064698            0.252451   \n",
       "                  FRO31317            0.066583            0.281915   \n",
       "                  SNA72163            0.067211            0.383513   \n",
       "                  ELE56788            0.067211            0.301408   \n",
       "                  GRO46854            0.068467            0.236443   \n",
       "...                                        ...                 ...   \n",
       "FRO19221 SNA53220 SNA93860            0.735484            0.754967   \n",
       "DAI42083 DAI62779 DAI92600            0.897436            0.410156   \n",
       "DAI88079 ELE17451 FRO40251            0.991935            0.275785   \n",
       "DAI75645 DAI88079 FRO40251            0.993289            0.118022   \n",
       "DAI62779 DAI88079 FRO40251            1.000000            0.109346   \n",
       "\n",
       "                            confidence_order_3  \n",
       "DAI62779 ELE17451 SNA90094            0.565934  \n",
       "                  FRO31317            0.295265  \n",
       "                  SNA72163            0.393382  \n",
       "                  ELE56788            0.514423  \n",
       "                  GRO46854            0.521531  \n",
       "...                                        ...  \n",
       "FRO19221 SNA53220 SNA93860            0.448819  \n",
       "DAI42083 DAI62779 DAI92600            0.593220  \n",
       "DAI88079 ELE17451 FRO40251            0.176471  \n",
       "DAI75645 DAI88079 FRO40251            0.331839  \n",
       "DAI62779 DAI88079 FRO40251            0.262332  \n",
       "\n",
       "[233 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_3_with_confidence = itemset_3.copy()\n",
    "\n",
    "itemset_3_with_confidence[\"confidence_order_1\"] = confidence_order_1\n",
    "itemset_3_with_confidence[\"confidence_order_2\"] = confidence_order_2\n",
    "itemset_3_with_confidence[\"confidence_order_3\"] = confidence_order_3\n",
    "\n",
    "itemset_3_with_confidence.sort_values(\"confidence_order_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus on the following 3-itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = (\"DAI42083\", \"DAI62779\", \"DAI92600\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the lift\n",
    "\n",
    "$$\\displaystyle \\frac{\\text{Confidence of Item 1 implies Item 2}}{\\text{Support of Item 2}}$$\n",
    "\n",
    "We have three cases for the value of the lift\n",
    "\n",
    "- If `Item 1, Item 2` had no association to `Item 3`, then the lift would be around 1. \n",
    "- If `Item 1, Item 2` imply that `Item 3` is less likely to be in the basket, then the lift would be less than 1.  \n",
    "- If `Item 1, Item 2` imply that `Item 3` is more likely to be in the basket, then the lift would be greater than 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.851501439736737"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator = len(itemset_1.loc[items[2], \"transactions\"]) / number_of_transactions\n",
    "\n",
    "lift = itemset_3_with_confidence.loc[items, \"confidence_order_1\"] / denominator\n",
    "lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the conviction.\n",
    "\n",
    "$$\\displaystyle \\frac{1}{\\text{Lift of Item 1, Item 2 imply not Item 3}}$$\n",
    "\n",
    "We have three cases for the value of the conviction\n",
    "\n",
    "- If `Item 1, Item 2` had no association to `Item 3`, then the conviction would be around 1. \n",
    "- If `Item 1, Item 2` imply that `Item 3` is more likely to be absent from the basket, then the conviction would be less than 1.  \n",
    "- If `Item 1, Item 2` imply that `Item 3` is less likely to be absent from the basket, then the lift would be greater than 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.456882415356421"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator =  1 - itemset_3_with_confidence.loc[items, \"confidence_order_1\"] \n",
    "numerator = 1 - (len(itemset_1.loc[items[2], \"transactions\"]) / number_of_transactions)\n",
    "\n",
    "conviction = numerator / denominator\n",
    "conviction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "If we want to scale the datasets, then we should try to use Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the the MLlib component of Spark has support for market basket analysis. Spark implements the FPGrowth approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[FRO11987, ELE17451, ELE89019, SNA90258, GRO99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[GRO99222, GRO12298, FRO12685, ELE91550, SNA11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[ELE17451, GRO73461, DAI22896, SNA99873, FRO86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[ELE17451, ELE37798, FRO86643, GRO56989, ELE23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[ELE17451, SNA69641, FRO86643, FRO78087, SNA11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31096</th>\n",
       "      <td>31096</td>\n",
       "      <td>[SNA30755, ELE97341, DAI42493, ELE74009, DAI22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>31097</td>\n",
       "      <td>[DAI87693, DAI35347, FRO31317, GRO21037, GRO88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>31098</td>\n",
       "      <td>[FRO53271, ELE53126, FRO31317, DAI83948, GRO88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>31099</td>\n",
       "      <td>[FRO41319, ELE14480, SNA62128, ELE92920, FRO99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31100</th>\n",
       "      <td>31100</td>\n",
       "      <td>[DAI45339, SNA59903, DAI62779, DAI92600, DAI42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       transaction                                              items\n",
       "0                0  [FRO11987, ELE17451, ELE89019, SNA90258, GRO99...\n",
       "1                1  [GRO99222, GRO12298, FRO12685, ELE91550, SNA11...\n",
       "2                2  [ELE17451, GRO73461, DAI22896, SNA99873, FRO86...\n",
       "3                3  [ELE17451, ELE37798, FRO86643, GRO56989, ELE23...\n",
       "4                4  [ELE17451, SNA69641, FRO86643, FRO78087, SNA11...\n",
       "...            ...                                                ...\n",
       "31096        31096  [SNA30755, ELE97341, DAI42493, ELE74009, DAI22...\n",
       "31097        31097  [DAI87693, DAI35347, FRO31317, GRO21037, GRO88...\n",
       "31098        31098  [FRO53271, ELE53126, FRO31317, DAI83948, GRO88...\n",
       "31099        31099  [FRO41319, ELE14480, SNA62128, ELE92920, FRO99...\n",
       "31100        31100  [DAI45339, SNA59903, DAI62779, DAI92600, DAI42...\n",
       "\n",
       "[31101 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets = pd.Series(transactions)\n",
    "baskets = baskets.reset_index()\n",
    "baskets.columns = [\"transaction\", \"items\"]\n",
    "baskets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Spark does not support a variety of data types, we need to work with strings for the `transaction` column and lists for the `items` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets[\"items\"] = baskets[\"items\"].apply(lambda x : list(set(x)))\n",
    "baskets[\"transaction\"] = baskets[\"transaction\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert from a `pandas` table to a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = spark.createDataFrame(baskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the MLlib package to generate a model implementing FPGrowth approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = pyspark.ml.fpm.FPGrowth(itemsCol=\"items\", minSupport=0.003, minConfidence=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify \n",
    "\n",
    "- data : Spark DataFrame `baskets`\n",
    "- minimum support : 0.3\\%\n",
    "- minimum confidence : 90\\%\n",
    "\n",
    "We need to fit the model to the data meaning we need to allow the model to deterine the frequent patterns in the Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fpGrowth.fit(baskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having fit the model, we can show the frequent $k$-itemsets for any value of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               items|freq|\n",
      "+--------------------+----+\n",
      "|          [FRO89565]| 516|\n",
      "|[FRO89565, ELE17451]| 104|\n",
      "|[FRO89565, ELE32164]| 137|\n",
      "|[FRO89565, FRO40251]| 110|\n",
      "|[FRO89565, DAI62779]| 158|\n",
      "|          [ELE85027]| 478|\n",
      "|[ELE85027, ELE20847]|  99|\n",
      "|[ELE85027, DAI62779]| 119|\n",
      "|          [GRO99635]| 120|\n",
      "|          [FRO48038]| 327|\n",
      "|[FRO48038, FRO43226]| 105|\n",
      "|          [SNA40058]| 118|\n",
      "|          [DAI11778]| 117|\n",
      "|          [ELE20202]| 317|\n",
      "|          [GRO75758]| 163|\n",
      "|          [FRO99783]| 764|\n",
      "|[FRO99783, FRO35904]| 122|\n",
      "|[FRO99783, ELE17451]| 108|\n",
      "|[FRO99783, FRO85978]|  97|\n",
      "|[FRO99783, GRO46854]| 128|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show all association rules with at least 90\\% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+------------------+\n",
      "|          antecedent|consequent|        confidence|              lift|\n",
      "+--------------------+----------+------------------+------------------+\n",
      "|          [GRO85051]|[FRO40251]| 0.999176276771005|  8.00705523933394|\n",
      "|[DAI23334, ELE17451]|[DAI62779]|              0.97|4.5249692515374225|\n",
      "|[GRO85051, SNA803...|[FRO40251]|               1.0| 8.013656274156146|\n",
      "|[ELE20847, GRO85051]|[FRO40251]|               1.0| 8.013656274156146|\n",
      "|[ELE92920, DAI83733]|[DAI62779]|0.9279279279279279| 4.328706537646091|\n",
      "|[GRO85051, DAI62779]|[FRO40251]|0.9973821989528796| 7.992678116370397|\n",
      "|[SNA18336, GRO81087]|[ELE92920]|0.9313725490196079|24.199346405228756|\n",
      "|[SNA18336, GRO81087]|[DAI62779]|0.9313725490196079| 4.344775408288409|\n",
      "|[GRO85051, GRO38814]|[FRO40251]|               1.0| 8.013656274156146|\n",
      "|[DAI83948, GRO85051]|[FRO40251]|               1.0| 8.013656274156146|\n",
      "|[FRO92469, SNA803...|[FRO40251]|0.9652173913043478| 7.734920403750714|\n",
      "|[SNA18336, ELE17451]|[DAI62779]|0.9138576779026217| 4.263069992567787|\n",
      "|[ELE59028, SNA938...|[DAI62779]|0.9672131147540983|4.5119686638618886|\n",
      "|[DAI23334, ELE92920]|[DAI62779]|               1.0| 4.664916754162292|\n",
      "|[SNA18336, GRO15017]|[DAI62779]|0.9292035398230089| 4.334657160947262|\n",
      "|[DAI88079, ELE17451]|[FRO40251]|0.9919354838709677| 7.949030013880693|\n",
      "|[ELE92920, DAI85309]|[DAI62779]|0.9502487562189055| 4.432831343507451|\n",
      "|[FRO92469, DAI62779]|[FRO40251]|0.9834710743801653| 7.881199145657697|\n",
      "|[SNA18336, ELE92920]|[DAI62779]|0.9494505494505494| 4.429107775380461|\n",
      "|[SNA18336, ELE929...|[DAI62779]|               1.0| 4.664916754162292|\n",
      "+--------------------+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that MLlib will compute the lift for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+\n",
      "|transaction|               items|prediction|\n",
      "+-----------+--------------------+----------+\n",
      "|          0|[ELE17451, ELE890...|        []|\n",
      "|          1|[SNA11465, GRO122...|        []|\n",
      "|          2|[ELE17451, SNA998...|        []|\n",
      "|          3|[SNA11465, ELE233...|        []|\n",
      "|          4|[SNA11465, ELE174...|        []|\n",
      "|          5|[FRO18919, ELE174...|        []|\n",
      "|          6|[SNA85662, ELE233...|        []|\n",
      "|          7|[DAI14125, FRO189...|        []|\n",
      "|          8|[SNA85662, ELE174...|        []|\n",
      "|          9|[ELE17451, GRO947...|        []|\n",
      "|         10|[DAI92253, ELE174...|        []|\n",
      "|         11|[DAI92253, ELE174...|        []|\n",
      "|         12|[ELE27376, FRO780...|        []|\n",
      "|         13|[DAI50913, ELE174...|        []|\n",
      "|         14|[FRO18919, FRO866...|        []|\n",
      "|         15|[GRO48971, ELE174...|        []|\n",
      "|         16|[FRO18919, ELE174...|        []|\n",
      "|         17|[SNA11465, DAI957...|        []|\n",
      "|         18|[DAI44355, FRO780...|        []|\n",
      "|         19|[GRO36567, SNA915...|        []|\n",
      "+-----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(baskets).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the association rules to each transaction. Based on the association rules, Spark will generate all possible predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mggy-8411]",
   "language": "python",
   "name": "conda-env-mggy-8411-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
